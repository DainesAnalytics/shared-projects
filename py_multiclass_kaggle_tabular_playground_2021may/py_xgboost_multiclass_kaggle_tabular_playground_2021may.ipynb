{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "py_xgboost_multiclass_kaggle_tabular_playground_2021may.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVs0Qopg3l7w"
      },
      "source": [
        "### Multi-Class Model for Kaggle Tabular Playground Series May 2021 Using Python and XGBoost\n",
        "### David Lowe\n",
        "### July 9, 2021\n",
        "\n",
        "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. [https://machinelearningmastery.com/]\n",
        "\n",
        "SUMMARY: This project aims to construct a predictive model using various machine learning algorithms and document the end-to-end steps using a template. The Kaggle Tabular Playground May 2021 dataset is a multi-class modeling situation where we attempt to predict one of several (more than two) possible outcomes.\n",
        "\n",
        "INTRODUCTION: Kaggle wants to provide an approachable environment for relatively new people in their data science journey. Since January 2021, they have hosted playground-style competitions on Kaggle with fun but less complex, tabular datasets. The dataset used for this competition is synthetic but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.\n",
        "\n",
        "ANALYSIS: The performance of the preliminary XGBoost model achieved a logarithmic loss benchmark of 1.0995. After a series of tuning trials, the refined XGBoost model processed the training dataset with a final logarithmic loss score of 1.0936. When we applied the last model to Kaggle's test dataset, the model achieved a logarithmic loss of 1.0933.\n",
        "\n",
        "CONCLUSION: In this iteration, the XGBoost model appeared to be a suitable algorithm for modeling this dataset.\n",
        "\n",
        "Dataset Used: Kaggle Tabular Playground 2021 May Data Set\n",
        "\n",
        "Dataset ML Model: Multi-Class classification with categorical attributes\n",
        "\n",
        "Dataset Reference: https://www.kaggle.com/c/tabular-playground-series-may-2021/\n",
        "\n",
        "One potential source of performance benchmark: https://www.kaggle.com/c/tabular-playground-series-may-2021/leaderboard\n",
        "\n",
        "Any predictive modeling machine learning project generally can be broken down into about six major tasks:\n",
        "\n",
        "1. Prepare Environment\n",
        "2. Summarize and Visualize Data\n",
        "3. Pre-process Data\n",
        "4. Train and Evaluate Models\n",
        "5. Fine-tune and Improve Models\n",
        "6. Finalize Model and Present Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcvIFuk03l7z"
      },
      "source": [
        "## Task 1 - Prepare Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8WmuNd23l70"
      },
      "source": [
        "# Install the necessary packages for Colab\n",
        "# !pip install python-dotenv PyMySQL"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFWd7eph3l70",
        "outputId": "44216525-f15c-4793-82dc-2bd9bd278c52"
      },
      "source": [
        "# Retrieve the GPU information from Colab\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  8 13:32:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tWJ-QK63l71",
        "outputId": "d4d87bfb-2de5-4a54-aef6-32e1f4d725a0"
      },
      "source": [
        "# Retrieve the memory configuration from Colab\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "    print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "    print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "    print('re-execute this cell.')\n",
        "else:\n",
        "    print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMxv3rIM3l71",
        "outputId": "7b166927-57fe-4eaf-ddcb-800fb1b31ee0"
      },
      "source": [
        "# Retrieve the CPU information\n",
        "ncpu = !nproc\n",
        "print(\"The number of available CPUs is:\", ncpu[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of available CPUs is: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7LCAiYF3l72"
      },
      "source": [
        "### 1.a) Load libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcBsRRuj3l73"
      },
      "source": [
        "# Set the random seed number for reproducible results\n",
        "RNG_SEED = 888"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvqMowk53l73"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "from datetime import datetime\n",
        "# import boto3\n",
        "# from dotenv import load_dotenv\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import compose\n",
        "from sklearn import impute\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj9CEmZv3l74"
      },
      "source": [
        "### 1.b) Set up the controlling parameters and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37e7yBJt3l74"
      },
      "source": [
        "# Begin the timer for the script processing\n",
        "start_time_script = datetime.now()\n",
        "\n",
        "# Set up the number of CPU cores available for multi-thread processing\n",
        "N_JOBS = 1\n",
        "\n",
        "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
        "NOTIFY_STATUS = False\n",
        "\n",
        "# Set the percentage sizes for splitting the dataset\n",
        "TEST_SET_RATIO = 0.2\n",
        "VAL_SET_RATIO = 0.25\n",
        "\n",
        "# Set the number of folds for cross validation\n",
        "N_FOLDS = 5\n",
        "\n",
        "# Set various default modeling parameters\n",
        "SCORING_METRIC = 'neg_log_loss'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeabrzoC3l75"
      },
      "source": [
        "# Set up the email notification function\n",
        "def status_notify(msg_text):\n",
        "    access_key = os.environ.get('SNS_ACCESS_KEY')\n",
        "    secret_key = os.environ.get('SNS_SECRET_KEY')\n",
        "    aws_region = os.environ.get('SNS_AWS_REGION')\n",
        "    topic_arn = os.environ.get('SNS_TOPIC_ARN')\n",
        "    if (access_key is None) or (secret_key is None) or (aws_region is None):\n",
        "        sys.exit(\"Incomplete notification setup info. Script Processing Aborted!!!\")\n",
        "    sns = boto3.client('sns', aws_access_key_id=access_key, aws_secret_access_key=secret_key, region_name=aws_region)\n",
        "    response = sns.publish(TopicArn=topic_arn, Message=msg_text)\n",
        "    if response['ResponseMetadata']['HTTPStatusCode'] != 200 :\n",
        "        print('Status notification not OK with HTTP status code:', response['ResponseMetadata']['HTTPStatusCode'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LXEI2QY3l75"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 1 - Prepare Environment has begun! \" + datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iud46_Nn3l76"
      },
      "source": [
        "### 1.c) Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw8vysCp3l76",
        "outputId": "1180e9da-117b-421a-e217-48a3b1c34b0e"
      },
      "source": [
        "dataset_path = 'https://dainesanalytics.com/datasets/kaggle-tabular-playground-2021may/train.csv'\n",
        "df_dataset_import = pd.read_csv(dataset_path, index_col=False)\n",
        "\n",
        "# Take a peek at the dataframe after import\n",
        "print(df_dataset_import.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  feature_0  feature_1  ...  feature_48  feature_49   target\n",
            "0   0          0          0  ...           0           0  Class_2\n",
            "1   1          0          0  ...           0           0  Class_1\n",
            "2   2          0          0  ...           2           0  Class_1\n",
            "3   3          0          0  ...           1           0  Class_4\n",
            "4   4          0          0  ...           1           0  Class_2\n",
            "\n",
            "[5 rows x 52 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdseXAzd3l76",
        "outputId": "bed07ec9-a425-44f5-ac4c-8e055cf83b6d"
      },
      "source": [
        "df_dataset_import.info(verbose=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   id          100000 non-null  int64 \n",
            " 1   feature_0   100000 non-null  int64 \n",
            " 2   feature_1   100000 non-null  int64 \n",
            " 3   feature_2   100000 non-null  int64 \n",
            " 4   feature_3   100000 non-null  int64 \n",
            " 5   feature_4   100000 non-null  int64 \n",
            " 6   feature_5   100000 non-null  int64 \n",
            " 7   feature_6   100000 non-null  int64 \n",
            " 8   feature_7   100000 non-null  int64 \n",
            " 9   feature_8   100000 non-null  int64 \n",
            " 10  feature_9   100000 non-null  int64 \n",
            " 11  feature_10  100000 non-null  int64 \n",
            " 12  feature_11  100000 non-null  int64 \n",
            " 13  feature_12  100000 non-null  int64 \n",
            " 14  feature_13  100000 non-null  int64 \n",
            " 15  feature_14  100000 non-null  int64 \n",
            " 16  feature_15  100000 non-null  int64 \n",
            " 17  feature_16  100000 non-null  int64 \n",
            " 18  feature_17  100000 non-null  int64 \n",
            " 19  feature_18  100000 non-null  int64 \n",
            " 20  feature_19  100000 non-null  int64 \n",
            " 21  feature_20  100000 non-null  int64 \n",
            " 22  feature_21  100000 non-null  int64 \n",
            " 23  feature_22  100000 non-null  int64 \n",
            " 24  feature_23  100000 non-null  int64 \n",
            " 25  feature_24  100000 non-null  int64 \n",
            " 26  feature_25  100000 non-null  int64 \n",
            " 27  feature_26  100000 non-null  int64 \n",
            " 28  feature_27  100000 non-null  int64 \n",
            " 29  feature_28  100000 non-null  int64 \n",
            " 30  feature_29  100000 non-null  int64 \n",
            " 31  feature_30  100000 non-null  int64 \n",
            " 32  feature_31  100000 non-null  int64 \n",
            " 33  feature_32  100000 non-null  int64 \n",
            " 34  feature_33  100000 non-null  int64 \n",
            " 35  feature_34  100000 non-null  int64 \n",
            " 36  feature_35  100000 non-null  int64 \n",
            " 37  feature_36  100000 non-null  int64 \n",
            " 38  feature_37  100000 non-null  int64 \n",
            " 39  feature_38  100000 non-null  int64 \n",
            " 40  feature_39  100000 non-null  int64 \n",
            " 41  feature_40  100000 non-null  int64 \n",
            " 42  feature_41  100000 non-null  int64 \n",
            " 43  feature_42  100000 non-null  int64 \n",
            " 44  feature_43  100000 non-null  int64 \n",
            " 45  feature_44  100000 non-null  int64 \n",
            " 46  feature_45  100000 non-null  int64 \n",
            " 47  feature_46  100000 non-null  int64 \n",
            " 48  feature_47  100000 non-null  int64 \n",
            " 49  feature_48  100000 non-null  int64 \n",
            " 50  feature_49  100000 non-null  int64 \n",
            " 51  target      100000 non-null  object\n",
            "dtypes: int64(51), object(1)\n",
            "memory usage: 39.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dut08ci_3l77",
        "outputId": "e1ee2ad5-feef-43b7-98e9-f540a1d3840b"
      },
      "source": [
        "print(df_dataset_import.describe())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  id      feature_0  ...     feature_48    feature_49\n",
            "count  100000.000000  100000.000000  ...  100000.000000  100000.00000\n",
            "mean    49999.500000       0.257830  ...       0.970850       0.55712\n",
            "std     28867.657797       0.929033  ...       2.576615       1.68093\n",
            "min         0.000000       0.000000  ...       0.000000       0.00000\n",
            "25%     24999.750000       0.000000  ...       0.000000       0.00000\n",
            "50%     49999.500000       0.000000  ...       0.000000       0.00000\n",
            "75%     74999.250000       0.000000  ...       1.000000       0.00000\n",
            "max     99999.000000      10.000000  ...      44.000000      20.00000\n",
            "\n",
            "[8 rows x 51 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j5yMdxL3l77",
        "outputId": "4ee514eb-e01c-4b99-e029-b21d647a5aca"
      },
      "source": [
        "print(df_dataset_import.isnull().sum())\n",
        "print('Total number of NaN in the dataframe: ', df_dataset_import.isnull().sum().sum())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id            0\n",
            "feature_0     0\n",
            "feature_1     0\n",
            "feature_2     0\n",
            "feature_3     0\n",
            "feature_4     0\n",
            "feature_5     0\n",
            "feature_6     0\n",
            "feature_7     0\n",
            "feature_8     0\n",
            "feature_9     0\n",
            "feature_10    0\n",
            "feature_11    0\n",
            "feature_12    0\n",
            "feature_13    0\n",
            "feature_14    0\n",
            "feature_15    0\n",
            "feature_16    0\n",
            "feature_17    0\n",
            "feature_18    0\n",
            "feature_19    0\n",
            "feature_20    0\n",
            "feature_21    0\n",
            "feature_22    0\n",
            "feature_23    0\n",
            "feature_24    0\n",
            "feature_25    0\n",
            "feature_26    0\n",
            "feature_27    0\n",
            "feature_28    0\n",
            "feature_29    0\n",
            "feature_30    0\n",
            "feature_31    0\n",
            "feature_32    0\n",
            "feature_33    0\n",
            "feature_34    0\n",
            "feature_35    0\n",
            "feature_36    0\n",
            "feature_37    0\n",
            "feature_38    0\n",
            "feature_39    0\n",
            "feature_40    0\n",
            "feature_41    0\n",
            "feature_42    0\n",
            "feature_43    0\n",
            "feature_44    0\n",
            "feature_45    0\n",
            "feature_46    0\n",
            "feature_47    0\n",
            "feature_48    0\n",
            "feature_49    0\n",
            "target        0\n",
            "dtype: int64\n",
            "Total number of NaN in the dataframe:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxxn8gnj3l78"
      },
      "source": [
        "### 1.d) Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osjQPBQY3l78",
        "outputId": "b49ed50b-f212-45c8-af79-e0c0219b6cc1"
      },
      "source": [
        "# Dropping features\n",
        "df_dataset_import.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# Convert columns from one data type to another\n",
        "train_feature_list = list(df_dataset_import.columns)\n",
        "for feature in train_feature_list:\n",
        "    df_dataset_import[feature] = df_dataset_import[feature].astype('category')\n",
        "\n",
        "# Take a peek at the dataframe after cleaning\n",
        "print(df_dataset_import.head())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  feature_0 feature_1 feature_2  ... feature_48 feature_49   target\n",
            "0         0         0         1  ...          0          0  Class_2\n",
            "1         0         0         0  ...          0          0  Class_1\n",
            "2         0         0         0  ...          2          0  Class_1\n",
            "3         0         0         0  ...          1          0  Class_4\n",
            "4         0         0         0  ...          1          0  Class_2\n",
            "\n",
            "[5 rows x 51 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t36Yn9gl3l78",
        "outputId": "7fff05a3-3acf-4cfb-c7db-86cc511db1ee"
      },
      "source": [
        "df_dataset_import.info(verbose=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 51 columns):\n",
            " #   Column      Non-Null Count   Dtype   \n",
            "---  ------      --------------   -----   \n",
            " 0   feature_0   100000 non-null  category\n",
            " 1   feature_1   100000 non-null  category\n",
            " 2   feature_2   100000 non-null  category\n",
            " 3   feature_3   100000 non-null  category\n",
            " 4   feature_4   100000 non-null  category\n",
            " 5   feature_5   100000 non-null  category\n",
            " 6   feature_6   100000 non-null  category\n",
            " 7   feature_7   100000 non-null  category\n",
            " 8   feature_8   100000 non-null  category\n",
            " 9   feature_9   100000 non-null  category\n",
            " 10  feature_10  100000 non-null  category\n",
            " 11  feature_11  100000 non-null  category\n",
            " 12  feature_12  100000 non-null  category\n",
            " 13  feature_13  100000 non-null  category\n",
            " 14  feature_14  100000 non-null  category\n",
            " 15  feature_15  100000 non-null  category\n",
            " 16  feature_16  100000 non-null  category\n",
            " 17  feature_17  100000 non-null  category\n",
            " 18  feature_18  100000 non-null  category\n",
            " 19  feature_19  100000 non-null  category\n",
            " 20  feature_20  100000 non-null  category\n",
            " 21  feature_21  100000 non-null  category\n",
            " 22  feature_22  100000 non-null  category\n",
            " 23  feature_23  100000 non-null  category\n",
            " 24  feature_24  100000 non-null  category\n",
            " 25  feature_25  100000 non-null  category\n",
            " 26  feature_26  100000 non-null  category\n",
            " 27  feature_27  100000 non-null  category\n",
            " 28  feature_28  100000 non-null  category\n",
            " 29  feature_29  100000 non-null  category\n",
            " 30  feature_30  100000 non-null  category\n",
            " 31  feature_31  100000 non-null  category\n",
            " 32  feature_32  100000 non-null  category\n",
            " 33  feature_33  100000 non-null  category\n",
            " 34  feature_34  100000 non-null  category\n",
            " 35  feature_35  100000 non-null  category\n",
            " 36  feature_36  100000 non-null  category\n",
            " 37  feature_37  100000 non-null  category\n",
            " 38  feature_38  100000 non-null  category\n",
            " 39  feature_39  100000 non-null  category\n",
            " 40  feature_40  100000 non-null  category\n",
            " 41  feature_41  100000 non-null  category\n",
            " 42  feature_42  100000 non-null  category\n",
            " 43  feature_43  100000 non-null  category\n",
            " 44  feature_44  100000 non-null  category\n",
            " 45  feature_45  100000 non-null  category\n",
            " 46  feature_46  100000 non-null  category\n",
            " 47  feature_47  100000 non-null  category\n",
            " 48  feature_48  100000 non-null  category\n",
            " 49  feature_49  100000 non-null  category\n",
            " 50  target      100000 non-null  category\n",
            "dtypes: category(51)\n",
            "memory usage: 4.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FFwZYXG3l79",
        "outputId": "b7b42247-e3e9-4fc1-f275-45391bd15505"
      },
      "source": [
        "print(df_dataset_import.describe())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        feature_0  feature_1  feature_2  ...  feature_48  feature_49   target\n",
            "count      100000     100000     100000  ...      100000      100000   100000\n",
            "unique         11         31          7  ...          45          21        4\n",
            "top             0          0          0  ...           0           0  Class_2\n",
            "freq        88473      89014      93492  ...       67780       80514    57497\n",
            "\n",
            "[4 rows x 51 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QMi80kq3l79",
        "outputId": "d9215cd3-e6a0-4b4f-cd93-409cbec91269"
      },
      "source": [
        "print(df_dataset_import.isnull().sum())\n",
        "print('Total number of NaN in the dataframe: ', df_dataset_import.isnull().sum().sum())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature_0     0\n",
            "feature_1     0\n",
            "feature_2     0\n",
            "feature_3     0\n",
            "feature_4     0\n",
            "feature_5     0\n",
            "feature_6     0\n",
            "feature_7     0\n",
            "feature_8     0\n",
            "feature_9     0\n",
            "feature_10    0\n",
            "feature_11    0\n",
            "feature_12    0\n",
            "feature_13    0\n",
            "feature_14    0\n",
            "feature_15    0\n",
            "feature_16    0\n",
            "feature_17    0\n",
            "feature_18    0\n",
            "feature_19    0\n",
            "feature_20    0\n",
            "feature_21    0\n",
            "feature_22    0\n",
            "feature_23    0\n",
            "feature_24    0\n",
            "feature_25    0\n",
            "feature_26    0\n",
            "feature_27    0\n",
            "feature_28    0\n",
            "feature_29    0\n",
            "feature_30    0\n",
            "feature_31    0\n",
            "feature_32    0\n",
            "feature_33    0\n",
            "feature_34    0\n",
            "feature_35    0\n",
            "feature_36    0\n",
            "feature_37    0\n",
            "feature_38    0\n",
            "feature_39    0\n",
            "feature_40    0\n",
            "feature_41    0\n",
            "feature_42    0\n",
            "feature_43    0\n",
            "feature_44    0\n",
            "feature_45    0\n",
            "feature_46    0\n",
            "feature_47    0\n",
            "feature_48    0\n",
            "feature_49    0\n",
            "target        0\n",
            "dtype: int64\n",
            "Total number of NaN in the dataframe:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuh6PSn53l79"
      },
      "source": [
        "### 1.e) Splitting Data into Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac66Lgmn3l79"
      },
      "source": [
        "# Use variable total_column_count to hold the number of columns in the dataframe\n",
        "total_column_count = len(df_dataset_import.columns)\n",
        "\n",
        "# Set up variable total_feature_count for the total number of attribute columns\n",
        "total_feature_count = total_column_count-1\n",
        "\n",
        "# target_column_position variable indicates the column location of the target/class variable\n",
        "# If the first column, set target_column_position to 1. If the last column, set target_column_position to total_column_count\n",
        "# If (target_column_position <> 1) and (target_column_position <> total_column_count), be aware when slicing up the dataframes for visualization\n",
        "target_column_position = total_column_count"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okf69cJ-3l7-",
        "outputId": "e21f8ee2-f633-4040-9d3d-9e3fe3a1c9d7"
      },
      "source": [
        "# We create attribute-only and target-only datasets (df_features_train and df_target_train)\n",
        "# for various visualization and cleaning/transformation operations\n",
        "\n",
        "if target_column_position == total_column_count:\n",
        "    df_features_train = df_dataset_import.iloc[:,0:total_feature_count]\n",
        "    df_target_train = df_dataset_import.iloc[:,total_feature_count]\n",
        "else:\n",
        "    df_features_train = df_dataset_import.iloc[:,1:total_column_count]\n",
        "    df_target_train = df_dataset_import.iloc[:,0]\n",
        "\n",
        "print(\"df_dataset_import.shape: {} df_features_train.shape: {} df_target_train.shape: {}\".format(df_dataset_import.shape, df_features_train.shape, df_target_train.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_dataset_import.shape: (100000, 51) df_features_train.shape: (100000, 50) df_target_train.shape: (100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_ha_1jD3l7-"
      },
      "source": [
        "### 1.f) Set up the parameters for data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZU3DZ3D3l7-"
      },
      "source": [
        "# Set up the number of row and columns for visualization display. display_rows * display_columns should be >= total_feature_count\n",
        "display_columns = 4\n",
        "if total_feature_count % display_columns == 0 :\n",
        "    display_rows = total_feature_count // display_columns\n",
        "else :\n",
        "    display_rows = (total_feature_count // display_columns) + 1\n",
        "\n",
        "# Set figure width to display the data visualization plots\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = display_columns * 4\n",
        "fig_size[1] = display_rows * 4\n",
        "plt.rcParams[\"figure.figsize\"] = fig_size"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACP83VhH3l7-"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 1 - Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZevOIQL3l7_"
      },
      "source": [
        "## Task 2 - Summarize and Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLt0NpWy3l7_"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 2 - Summarize and Visualize Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVURY0Ba3l7_"
      },
      "source": [
        "# # Histograms for each attribute\n",
        "# df_features_train.plot(kind='hist', subplots=True, layout=(display_rows, display_columns))\n",
        "# plt.show()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m92aROlh3l8A"
      },
      "source": [
        "# # Box and Whisker plot for each attribute\n",
        "# df_features_train.plot(kind='box', subplots=True, layout=(display_rows, display_columns))\n",
        "# plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r8q4sgU3l8A"
      },
      "source": [
        "# # Correlation matrix\n",
        "# fig = plt.figure(figsize=(20, 20))\n",
        "# correlations = df_features_train.corr(method='pearson')\n",
        "# sns.heatmap(correlations, annot=True, cmap=plt.cm.PuBu)\n",
        "# plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47zwOFBY3l8A"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 2 - Summarize and Visualize Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMRuoNay3l8B"
      },
      "source": [
        "## Task 3 - Pre-process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vQJ1B6d3l8B"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 3 - Pre-process Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLUO6zME3l8B"
      },
      "source": [
        "### 3.a) Splitting Data into Training and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vg3u6An3l8B"
      },
      "source": [
        "# Not applicable for this iteration of the project"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJKVMdU-3l8B"
      },
      "source": [
        "### 3.b) Feature Scaling and Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdJRYIRo3l8B",
        "outputId": "8ea7e336-c39b-40ed-8245-ea9fa4df9580"
      },
      "source": [
        "# Compose pipeline for the numerical and categorical features (Block #1 of 2)\n",
        "numeric_columns = df_features_train.select_dtypes(include=['int64','float64']).columns\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    # ('imputer', impute.SimpleImputer(strategy=\"median\")),\n",
        "    ('scaler', preprocessing.MinMaxScaler())\n",
        "])\n",
        "categorical_columns = df_features_train.select_dtypes(include=['object','bool','category']).columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    # ('imputer', impute.SimpleImputer(strategy='constant', fill_value='UKNOWN')),\n",
        "    ('onehot', preprocessing.OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "print(\"Number of numerical columns:\", len(numeric_columns))\n",
        "print(\"Number of categorical columns:\", len(categorical_columns))\n",
        "print(\"Total number of columns in the feature dataframe:\", df_features_train.shape[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns: 0\n",
            "Number of categorical columns: 50\n",
            "Total number of columns in the feature dataframe: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPyFhjc43l8C",
        "outputId": "296bfddc-c04e-4221-a16a-7b2751ba581c"
      },
      "source": [
        "# Compose pipeline for the numerical and categorical features (Block #2 of 2)\n",
        "preprocessor = compose.ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_columns),\n",
        "    ('cat', categorical_transformer, categorical_columns)\n",
        "])\n",
        "\n",
        "# Display the shapes of the training dataset for final inspection\n",
        "array_features_train = preprocessor.fit_transform(df_features_train)\n",
        "print(\"Transformed features from df_features_train.shape: {} to array_features_train.shape: {}\".format(df_features_train.shape, array_features_train.shape))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformed features from df_features_train.shape: (100000, 50) to array_features_train.shape: (100000, 1355)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj81IbIC3l8C"
      },
      "source": [
        "### 3.c) Training Data Balancing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke6jtd9V3l8C"
      },
      "source": [
        "# Not applicable for this iteration of the project"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR-zmIHD3l8C"
      },
      "source": [
        "### 3.d) Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTX0mnVe3l8D"
      },
      "source": [
        "# Not applicable for this iteration of the project"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGAvblp03l8D"
      },
      "source": [
        "### 3.e) Display the Final Datasets for Model-Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EourCr333l8D",
        "outputId": "b70b8ab4-9962-48f6-c432-cd81b259aa51"
      },
      "source": [
        "# Finalize the training and validation datasets for the modeling activities\n",
        "# array_features_train = df_features_train.to_numpy()\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "array_target_train = label_encoder.fit_transform(df_target_train)\n",
        "print(\"array_features_train.shape: {} array_target_train.shape: {}\".format(array_features_train.shape, array_target_train.shape))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array_features_train.shape: (100000, 1355) array_target_train.shape: (100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_DPVC0t3l8D"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 3 - Pre-process Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4q-C4XU3l8D"
      },
      "source": [
        "## Task 4 - Train and Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_zb8Pq13l8D"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 4 - Train and Evaluate Models has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGkybORs3l8E"
      },
      "source": [
        "### 4.a) Set test options and evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbls2rTF3l8E"
      },
      "source": [
        "# Set up Algorithms Spot-Checking Array\n",
        "start_time_training = datetime.now()\n",
        "train_models = [('XGB', XGBClassifier(random_state=RNG_SEED, n_jobs=N_JOBS, objective='multi:softmax', tree_method='gpu_hist'))]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCpdezoJ3l8E",
        "outputId": "18bcc2a3-abe9-46ae-e094-942300a28eb2"
      },
      "source": [
        "# Generate model in turn\n",
        "for name, model in train_models:\n",
        "\tif NOTIFY_STATUS: status_notify(\"Algorithm \"+name+\" modeling has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
        "\tstart_time_module = datetime.now()\n",
        "\tkfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RNG_SEED)\n",
        "\tcv_results = cross_val_score(model, array_features_train, array_target_train, cv=kfold, scoring=SCORING_METRIC, n_jobs=N_JOBS, verbose=1)\n",
        "\tprint(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n",
        "\tprint(model)\n",
        "\tprint ('Model training time:', (datetime.now() - start_time_module), '\\n')\n",
        "\tif NOTIFY_STATUS: status_notify(\"Algorithm \"+name+\" modeling completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XGB: -1.099516 (0.000745)\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='multi:softmax', random_state=888,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, tree_method='gpu_hist', verbosity=1)\n",
            "Model training time: 0:01:24.896561 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0bV856P3l8F"
      },
      "source": [
        "### 4.b) Algorithm Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u73tMrgV3l8F"
      },
      "source": [
        "# Set up the comparison array\n",
        "tune_results = []\n",
        "tune_model_names = []"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxAHVg7Q3l8G",
        "outputId": "25c32b27-e8a8-4939-8afa-cc305a2d23be"
      },
      "source": [
        "# Tuning XGBoost n_estimators, max_depth, and min_child_weight parameters\n",
        "start_time_module = datetime.now()\n",
        "if NOTIFY_STATUS: status_notify(\"Algorithm tuning iteration #1 has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
        "\n",
        "tune_model1 = XGBClassifier(random_state=RNG_SEED, n_jobs=N_JOBS, objective='multi:softmax', tree_method='gpu_hist')\n",
        "tune_model_names.append('XGB_1')\n",
        "paramGrid1 = dict(n_estimators=range(100, 501, 100),\n",
        "                  max_depth=np.array([3, 6, 9]),\n",
        "                  min_child_weight=np.array([4, 5, 6]))\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RNG_SEED)\n",
        "grid1 = GridSearchCV(estimator=tune_model1, param_grid=paramGrid1, scoring=SCORING_METRIC, cv=kfold, n_jobs=N_JOBS, verbose=1)\n",
        "grid_result1 = grid1.fit(array_features_train, array_target_train)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
        "tune_results.append(grid_result1.cv_results_['mean_test_score'])\n",
        "means = grid_result1.cv_results_['mean_test_score']\n",
        "stds = grid_result1.cv_results_['std_test_score']\n",
        "params = grid_result1.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "print ('Model training time:',(datetime.now() - start_time_module))\n",
        "if NOTIFY_STATUS: status_notify(\"Algorithm tuning iteration #1 completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 145.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: -1.094362 using {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 500}\n",
            "-1.099563 (0.000728) with: {'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100}\n",
            "-1.096165 (0.000875) with: {'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 200}\n",
            "-1.094993 (0.000904) with: {'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 300}\n",
            "-1.094598 (0.001029) with: {'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 400}\n",
            "-1.094507 (0.001159) with: {'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 500}\n",
            "-1.099481 (0.000770) with: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 100}\n",
            "-1.096059 (0.000877) with: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 200}\n",
            "-1.094872 (0.000860) with: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 300}\n",
            "-1.094451 (0.000956) with: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 400}\n",
            "-1.094362 (0.001053) with: {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 500}\n",
            "-1.099534 (0.000723) with: {'max_depth': 3, 'min_child_weight': 6, 'n_estimators': 100}\n",
            "-1.096138 (0.000836) with: {'max_depth': 3, 'min_child_weight': 6, 'n_estimators': 200}\n",
            "-1.094926 (0.000848) with: {'max_depth': 3, 'min_child_weight': 6, 'n_estimators': 300}\n",
            "-1.094573 (0.001029) with: {'max_depth': 3, 'min_child_weight': 6, 'n_estimators': 400}\n",
            "-1.094448 (0.001058) with: {'max_depth': 3, 'min_child_weight': 6, 'n_estimators': 500}\n",
            "-1.097327 (0.001154) with: {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 100}\n",
            "-1.096813 (0.001318) with: {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 200}\n",
            "-1.097394 (0.001592) with: {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 300}\n",
            "-1.098482 (0.001696) with: {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 400}\n",
            "-1.099913 (0.001796) with: {'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 500}\n",
            "-1.097271 (0.000999) with: {'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 100}\n",
            "-1.096672 (0.001176) with: {'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 200}\n",
            "-1.097434 (0.001316) with: {'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 300}\n",
            "-1.098678 (0.001446) with: {'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 400}\n",
            "-1.100126 (0.001628) with: {'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 500}\n",
            "-1.097375 (0.001105) with: {'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 100}\n",
            "-1.096902 (0.001281) with: {'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 200}\n",
            "-1.097539 (0.001295) with: {'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 300}\n",
            "-1.098711 (0.001384) with: {'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 400}\n",
            "-1.100249 (0.001492) with: {'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 500}\n",
            "-1.099030 (0.001387) with: {'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 100}\n",
            "-1.100695 (0.001524) with: {'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 200}\n",
            "-1.103215 (0.001784) with: {'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 300}\n",
            "-1.105943 (0.001741) with: {'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 400}\n",
            "-1.109190 (0.001992) with: {'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 500}\n",
            "-1.098735 (0.001268) with: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 100}\n",
            "-1.100199 (0.001343) with: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 200}\n",
            "-1.102665 (0.001473) with: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 300}\n",
            "-1.105657 (0.001614) with: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 400}\n",
            "-1.108768 (0.001878) with: {'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 500}\n",
            "-1.099158 (0.001068) with: {'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 100}\n",
            "-1.100718 (0.001287) with: {'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 200}\n",
            "-1.103258 (0.001358) with: {'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 300}\n",
            "-1.106165 (0.001591) with: {'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 400}\n",
            "-1.109251 (0.001846) with: {'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 500}\n",
            "Model training time: 2:26:28.709236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBQWedof87Bu",
        "outputId": "b6a6c744-43e5-42ca-d574-09b3ba3c6227"
      },
      "source": [
        "# Tuning XGBoost subsample and colsample_bytree parameters\n",
        "start_time_module = datetime.now()\n",
        "if NOTIFY_STATUS: status_notify(\"Algorithm tuning iteration #2 has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
        "\n",
        "tune_model2 = XGBClassifier(n_estimators=500, max_depth=3, min_child_weight=5,\n",
        "                            random_state=RNG_SEED, n_jobs=N_JOBS, objective='multi:softmax', tree_method='gpu_hist')\n",
        "tune_model_names.append('XGB_2')\n",
        "paramGrid2 = dict(subsample=np.array([0.7, 0.8, 0.9, 1.0]), colsample_bytree=np.array([0.7, 0.8, 0.9, 1.0]))\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RNG_SEED)\n",
        "grid2 = GridSearchCV(estimator=tune_model2, param_grid=paramGrid2, scoring=SCORING_METRIC, cv=kfold, n_jobs=N_JOBS, verbose=1)\n",
        "grid_result2 = grid2.fit(array_features_train, array_target_train)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
        "tune_results.append(grid_result2.cv_results_['mean_test_score'])\n",
        "means = grid_result2.cv_results_['mean_test_score']\n",
        "stds = grid_result2.cv_results_['std_test_score']\n",
        "params = grid_result2.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "print ('Model training time:',(datetime.now() - start_time_module))\n",
        "if NOTIFY_STATUS: status_notify(\"Algorithm tuning iteration #2 completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 63.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: -1.093614 using {'colsample_bytree': 0.7, 'subsample': 0.8}\n",
            "-1.093887 (0.001188) with: {'colsample_bytree': 0.7, 'subsample': 0.7}\n",
            "-1.093614 (0.001088) with: {'colsample_bytree': 0.7, 'subsample': 0.8}\n",
            "-1.093694 (0.001141) with: {'colsample_bytree': 0.7, 'subsample': 0.9}\n",
            "-1.094185 (0.000898) with: {'colsample_bytree': 0.7, 'subsample': 1.0}\n",
            "-1.093899 (0.000984) with: {'colsample_bytree': 0.8, 'subsample': 0.7}\n",
            "-1.093698 (0.001227) with: {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
            "-1.093722 (0.001227) with: {'colsample_bytree': 0.8, 'subsample': 0.9}\n",
            "-1.094342 (0.001091) with: {'colsample_bytree': 0.8, 'subsample': 1.0}\n",
            "-1.093872 (0.001132) with: {'colsample_bytree': 0.9, 'subsample': 0.7}\n",
            "-1.093888 (0.001184) with: {'colsample_bytree': 0.9, 'subsample': 0.8}\n",
            "-1.093763 (0.001258) with: {'colsample_bytree': 0.9, 'subsample': 0.9}\n",
            "-1.094220 (0.001095) with: {'colsample_bytree': 0.9, 'subsample': 1.0}\n",
            "-1.094033 (0.001121) with: {'colsample_bytree': 1.0, 'subsample': 0.7}\n",
            "-1.093896 (0.001160) with: {'colsample_bytree': 1.0, 'subsample': 0.8}\n",
            "-1.093829 (0.001018) with: {'colsample_bytree': 1.0, 'subsample': 0.9}\n",
            "-1.094362 (0.001053) with: {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
            "Model training time: 1:03:58.678257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-3L_3SiA5U9",
        "outputId": "6116dd91-0543-4bfe-af42-01810016c73a"
      },
      "source": [
        "# Tuning XGBoost subsample and colsample_bytree parameters\n",
        "start_time_module = datetime.now()\n",
        "if NOTIFY_STATUS: status_notify(\"Algorithm tuning iteration #2 has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
        "\n",
        "tune_model3 = XGBClassifier(n_estimators=500, max_depth=3, min_child_weight=5,\n",
        "                            colsample_bytree=0.7, subsample=0.8,\n",
        "                            random_state=RNG_SEED, n_jobs=N_JOBS, objective='multi:softmax', tree_method='gpu_hist')\n",
        "tune_model_names.append('XGB_3')\n",
        "paramGrid3 = dict(learning_rate=np.array([0.1, 0.05, 0.01, 0.005]))\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RNG_SEED)\n",
        "grid3 = GridSearchCV(estimator=tune_model3, param_grid=paramGrid3, scoring=SCORING_METRIC, cv=kfold, n_jobs=N_JOBS, verbose=1)\n",
        "grid_result3 = grid3.fit(array_features_train, array_target_train)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result3.best_score_, grid_result3.best_params_))\n",
        "tune_results.append(grid_result3.cv_results_['mean_test_score'])\n",
        "means = grid_result3.cv_results_['mean_test_score']\n",
        "stds = grid_result3.cv_results_['std_test_score']\n",
        "params = grid_result3.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "print ('Model training time:',(datetime.now() - start_time_module))\n",
        "if NOTIFY_STATUS: status_notify(\"Algorithm tuning iteration #3 completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 16.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: -1.093614 using {'learning_rate': 0.1}\n",
            "-1.093614 (0.001088) with: {'learning_rate': 0.1}\n",
            "-1.094342 (0.000837) with: {'learning_rate': 0.05}\n",
            "-1.104376 (0.000658) with: {'learning_rate': 0.01}\n",
            "-1.117167 (0.000534) with: {'learning_rate': 0.005}\n",
            "Model training time: 0:17:47.581214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeTnXsgJ3l8H"
      },
      "source": [
        "### 4.c) Compare Algorithms After Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "RqXMqwAb3l8H",
        "outputId": "66ecb0de-c983-43e1-a65a-72193b07f7bf"
      },
      "source": [
        "fig = plt.figure(figsize=(16,12))\n",
        "fig.suptitle('Algorithm Comparison - Post Tuning')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(tune_results)\n",
        "ax.set_xticklabels(tune_model_names)\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PxkOhNE3l8F"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 4 - Train and Evaluate Models completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIRMoNm63l8H"
      },
      "source": [
        "## Task 5 - Finalize Model and Present Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgw8i_ME3l8H"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 5 - Finalize Model and Present Analysis has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsQONLo33l8I"
      },
      "source": [
        "### 6.a) Train the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIDASCL13l8I",
        "outputId": "398122f1-4797-4a41-9e9b-b20ad7ea578d"
      },
      "source": [
        "final_model = XGBClassifier(n_estimators=500, max_depth=3, min_child_weight=5,\n",
        "                            colsample_bytree=0.7, subsample=0.8, learning_rate=0.1,\n",
        "                            random_state=RNG_SEED, n_jobs=N_JOBS, objective='multi:softmax', tree_method='gpu_hist')\n",
        "final_model.fit(array_features_train, array_target_train)\n",
        "print(final_model)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=5, missing=None, n_estimators=500, n_jobs=1,\n",
            "              nthread=None, objective='multi:softprob', random_state=888,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=0.8, tree_method='gpu_hist', verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzeEayxg3l8I"
      },
      "source": [
        "### 6.b) Load Test Dataset and Prepare the Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8S2vLNw3l8I",
        "outputId": "fd137481-cba1-4bcd-c5c6-79a4bfee1e10"
      },
      "source": [
        "dataset_path = 'https://dainesanalytics.com/datasets/kaggle-tabular-playground-2021may/test.csv'\n",
        "df_features_test = pd.read_csv(dataset_path, index_col=False)\n",
        "\n",
        "# Take a peek at the dataframe after import\n",
        "print(df_features_test.head())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       id  feature_0  feature_1  ...  feature_47  feature_48  feature_49\n",
            "0  100000          0          0  ...           0           0           0\n",
            "1  100001          0          0  ...           0           2           1\n",
            "2  100002          0          0  ...           0           6           0\n",
            "3  100003          0          0  ...           9          14           3\n",
            "4  100004          0          0  ...           0           0           0\n",
            "\n",
            "[5 rows x 51 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVrEdBfT3l8I",
        "outputId": "7e570b65-84af-4f5a-e9b1-2a18becbfb01"
      },
      "source": [
        "df_kaggle_submission = pd.DataFrame()\n",
        "df_kaggle_submission['id'] = df_features_test['id']\n",
        "print(df_kaggle_submission.head())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       id\n",
            "0  100000\n",
            "1  100001\n",
            "2  100002\n",
            "3  100003\n",
            "4  100004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JPFel4u3l8J",
        "outputId": "20bc1e3a-849d-43c3-b960-a60dbed06cbe"
      },
      "source": [
        "# Dropping features\n",
        "df_features_test.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# Convert columns from one data type to another\n",
        "test_feature_list = list(df_features_test.columns)\n",
        "for feature in test_feature_list:\n",
        "    df_features_test[feature] = df_features_test[feature].astype('category')\n",
        "\n",
        "# Take a peek at the dataframe after cleaning\n",
        "print(df_features_test.head())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  feature_0 feature_1 feature_2  ... feature_47 feature_48 feature_49\n",
            "0         0         0         0  ...          0          0          0\n",
            "1         0         0         1  ...          0          2          1\n",
            "2         0         0         0  ...          0          6          0\n",
            "3         0         0         0  ...          9         14          3\n",
            "4         0         0         0  ...          0          0          0\n",
            "\n",
            "[5 rows x 50 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avu1nEAa3l8J",
        "outputId": "d3de5deb-c9ab-42c2-cc05-fe3e59fbafa4"
      },
      "source": [
        "# Finalize the test dataset for the modeling testing\n",
        "array_features_test = preprocessor.transform(df_features_test)\n",
        "print(\"Transformed features from df_features_test.shape: {} to array_features_test.shape: {}\".format(df_features_test.shape, array_features_test.shape))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformed features from df_features_test.shape: (50000, 50) to array_features_test.shape: (50000, 1355)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5YNHp6S3l8J",
        "outputId": "7b96cc9b-40f0-442b-edf0-bd47696e11b5"
      },
      "source": [
        "# Make batched predictions\n",
        "test_predictions = final_model.predict_proba(array_features_test)\n",
        "print(test_predictions)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09385491 0.58056104 0.17459671 0.15098733]\n",
            " [0.05605949 0.74241316 0.11359467 0.08793265]\n",
            " [0.09122954 0.6083024  0.20229337 0.09817471]\n",
            " ...\n",
            " [0.07945924 0.5145897  0.22695062 0.1790004 ]\n",
            " [0.08627193 0.58040833 0.17085606 0.16246371]\n",
            " [0.08867138 0.5802119  0.21033989 0.12077679]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXmbWirt3l8J",
        "outputId": "fddddb0a-b686-4912-c693-3dad4d57c11e"
      },
      "source": [
        "df_kaggle_submission[['Class_1','Class_2','Class_3','Class_4']] = test_predictions\n",
        "print(df_kaggle_submission.head())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       id   Class_1   Class_2   Class_3   Class_4\n",
            "0  100000  0.093855  0.580561  0.174597  0.150987\n",
            "1  100001  0.056059  0.742413  0.113595  0.087933\n",
            "2  100002  0.091230  0.608302  0.202293  0.098175\n",
            "3  100003  0.075009  0.576091  0.262442  0.086458\n",
            "4  100004  0.076461  0.640460  0.180277  0.102802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-czkeOmO3l8K",
        "outputId": "d680480d-3bb3-47e4-84c9-0cd1b3d1b20d"
      },
      "source": [
        "submission_file = df_kaggle_submission.to_csv(header=True, index=False)\n",
        "filename = 'submission_' + datetime.now().strftime('%Y%m%d-%H%M') + '.csv'\n",
        "with open(filename, 'w') as f:\n",
        "    f.write(submission_file)\n",
        "    print('Completed writing output file: ' + filename)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed writing output file: submission_20210708-1733.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE7Ey5753l8K"
      },
      "source": [
        "if NOTIFY_STATUS: status_notify(\"Task 5 - Finalize Model and Present Analysis completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxfno4RT3l8K",
        "outputId": "212d20b8-3d4f-43bf-ad27-a623691d05bd"
      },
      "source": [
        "print ('Total time for the script:',(datetime.now() - start_time_script))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time for the script: 4:00:58.469273\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}